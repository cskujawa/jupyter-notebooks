{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d8891-7592-4aca-9203-721d36e33f60",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install transformers dependencies\n",
    "!pip install -qU transformers\n",
    "!pip install accelerate\n",
    "# Had to add in the install tensorflow (which should already be installed in this container) with the [and-cuda] to get some extra functions out of it\n",
    "!pip install tensorflow[and-cuda]\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91629e5-2e59-4f23-9b29-3647baf18d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install Huggingface dependency and login using token\n",
    "!pip install --upgrade huggingface_hub\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d913d9-8d60-4fc3-8a3e-cb57deadbf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "def summarize_code(code, model_name='microsoft/codebert-base'):\n",
    "    \"\"\"\n",
    "    Summarize the given piece of code using CodeBERT.\n",
    "\n",
    "    Args:\n",
    "    - code (str): The piece of code to summarize.\n",
    "    - model_name (str, optional): The model name of CodeBERT on Hugging Face. Defaults to 'microsoft/codebert-base'.\n",
    "\n",
    "    Returns:\n",
    "    - str: The generated summary of the code.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load tokenizer and model from Hugging Face\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    model = RobertaForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "    # Prepare the code for the model\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate a summary token by token (you may want to limit the length or add stopping conditions)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=50, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08528e7-62dd-4609-921d-5fda43ca43ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summarize_code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mdef fibonacci(n):\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    a, b = 0, 1\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    return a\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Print the summary\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msummarize_code\u001b[49m(code))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summarize_code' is not defined"
     ]
    }
   ],
   "source": [
    "# Example code to summarize\n",
    "code = \"\"\"\n",
    "def fibonacci(n):\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        a, b = b, a + b\n",
    "    return a\n",
    "\"\"\"\n",
    "\n",
    "# Print the summary\n",
    "print(summarize_code(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ebf9e2-bcce-41c2-bdcf-0404f6e9a230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
